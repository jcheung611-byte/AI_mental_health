# AI Voice Assistant - v0

A warm, safe AI voice assistant with emotional intelligence. Speak naturally and hear warm, helpful responses.

## âœ… Status: v0 Complete - All Phases Implemented

### Features

- ğŸ¤ **Voice Input**: Press and hold to speak
- ğŸ¯ **Speech-to-Text**: Powered by OpenAI Whisper
- ğŸ¤– **Warm AI Personality**: GPT-4 with emotional intelligence
- ğŸ”Š **Voice Output**: Natural-sounding TTS responses
- âš¡ **Full Loop**: Complete conversation in ~5 seconds
- ğŸ›¡ï¸ **Safety**: Built-in guardrails and error handling

## Quick Start

### 1. Install Dependencies

```bash
cd frontend
npm install
```

### 2. Set Up Environment

Copy the example env file:

```bash
cp .env.local.example .env.local
```

Edit `.env.local` and add your Portkey API key:

```
PORTKEY_API_KEY=your_actual_portkey_key_here
PORTKEY_BASE_URL=https://api.portkey.ai/v1
```

### 3. Run Development Server

```bash
npm run dev
```

### 4. Open the App

Navigate to [http://localhost:3000](http://localhost:3000)

### 5. Test the Voice Loop

1. Click and hold the "Hold to Talk" button
2. Speak into your microphone
3. Release the button
4. Watch as it:
   - Transcribes your speech
   - Gets an AI response
   - Speaks the response back to you

## Project Structure

```
frontend/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ index.tsx              # Main UI with full voice loop
â”‚   â”œâ”€â”€ _app.tsx               # App wrapper
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ transcribe.ts      # Whisper API endpoint
â”‚       â”œâ”€â”€ chat.ts            # GPT-4 chat endpoint
â”‚       â””â”€â”€ speak.ts           # TTS API endpoint
â”œâ”€â”€ components/
â”‚   â””â”€â”€ VoiceButton.tsx        # Push-to-talk button component
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ audioRecorder.ts       # MediaRecorder API wrapper
â”œâ”€â”€ styles/
â”‚   â””â”€â”€ globals.css            # Global styles with Tailwind
â”œâ”€â”€ package.json               # Dependencies
â”œâ”€â”€ tsconfig.json              # TypeScript config
â”œâ”€â”€ tailwind.config.js         # Tailwind config
â””â”€â”€ next.config.js             # Next.js config
```

## Tech Stack

- **Frontend**: Next.js 14 (Pages Router), React 18, TypeScript
- **Styling**: TailwindCSS
- **Voice APIs**: OpenAI (via Portkey)
  - Whisper (speech-to-text)
  - GPT-4 (conversation)
  - TTS (text-to-speech)
- **Audio**: Web Audio API, MediaRecorder

## AI Personality

The AI has a warm, emotionally intelligent personality with three implicit modes:

1. **Companion Mode**: Emotional support, validation, grounding
2. **Teacher Mode**: Step-by-step learning, no homework cheating
3. **Assistant Mode**: Planning, summaries, task breakdown

### Safety Features

- No romantic/dependency language
- Crisis support with professional help referrals
- No medical diagnoses
- Clear AI/human boundaries

## Development Phases (Completed)

- âœ… **Phase 1**: Audio recording with MediaRecorder API
- âœ… **Phase 2**: Transcription with Whisper
- âœ… **Phase 3**: Chat responses with GPT-4
- âœ… **Phase 4**: Text-to-speech playback
- âœ… **Phase 5**: Integration, polish, and error handling

## Troubleshooting

### No microphone access
- Check browser permissions
- Make sure you're using HTTPS or localhost
- Allow microphone access when prompted

### Transcription fails
- Speak clearly and loudly enough
- Make sure your recording is at least 1 second
- Check API key is configured correctly

### No audio playback
- Check browser audio isn't muted
- Try clicking on the page first (browsers require user interaction)
- Check developer console for errors

### API errors
- Verify your Portkey API key is correct in `.env.local`
- Check that you have API credits available
- Restart the dev server after changing `.env.local`

## What's Next (Future Phases)

### Memory & Context
- Conversation history
- User preferences storage
- Long-term memory system

### Advanced Features
- Multiple conversation turns
- Mode switching UI
- Voice selection
- Custom personality tuning
- Mobile app (React Native)

### Production Ready
- User authentication
- Database integration
- Better error recovery
- Performance optimization
- Deployment to Vercel

## API Usage

The app makes the following API calls per conversation:

1. **Whisper** (transcribe): ~$0.006 per minute of audio
2. **GPT-4** (chat): ~$0.03 per request
3. **TTS** (speak): ~$0.015 per 1000 characters

Estimated cost per conversation: **~$0.05**

## License

Personal project - not licensed for redistribution

## Acknowledgments

Built following the plan from `ChatGPT initial brainstorming.md` - a thoughtful approach to creating warm, safe AI interactions.
